{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CSVY for Python","text":"<p>CSV is a popular format for storing tabular data used in many disciplines. Metadata concerning the contents of the file is often included in the header, but it rarely follows a format that is machine readable - sometimes is not even human readable! In some cases, such information is provided in a separate file, which is not ideal as it is easy for data and metadata to get separated.</p> <p>CSVY is a small Python package to handle CSV files in which the metadata in the header is formatted in YAML. It supports reading/writing tabular data contained in numpy arrays, pandas DataFrames, polars DataFrames, and nested lists, as well as metadata using a standard python dictionary. Ultimately, it aims to incorporate information about the CSV dialect used and a Table Schema specifying the contents of each column to aid the reading and interpretation of the data.</p>"},{"location":"#installation","title":"Installation","text":"<p>'pycsvy' is available in PyPI therefore its installation is as easy as:</p> <pre><code>pip install pycsvy\n</code></pre> <p>In order to support reading into <code>numpy</code> arrays, <code>pandas</code> DataFrames or <code>polars</code> DataFrames, you will need to install those packages, too. This can be support by specifying extras, ie:</p> <pre><code>pip install pycsvy[pandas, polars]\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>In the simplest case, to save some data contained in <code>data</code> and some metadata contained in a <code>metadata</code> dictionary into a CSVY file <code>important_data.csv</code> (the extension is not relevant), just do the following:</p> <pre><code>import csvy\n\ncsvy.write(\"important_data.csv\", data, metadata)\n</code></pre> <p>The resulting file will have the YAML-formatted header in between <code>---</code> markers with, optionally, a comment character starting each header line. It could look something like the following:</p> <pre><code>---\nname: my-dataset\ntitle: Example file of csvy\ndescription: Show a csvy sample file.\nencoding: utf-8\nschema:\n  fields:\n  - name: Date\n    type: object\n  - name: WTI\n    type: number\n---\nDate,WTI\n1986-01-02,25.56\n1986-01-03,26.00\n1986-01-06,26.53\n1986-01-07,25.85\n1986-01-08,25.87\n</code></pre> <p>For reading the information back:</p> <pre><code>import csvy\n\n# To read into a numpy array\ndata, metadata = csvy.read_to_array(\"important_data.csv\")\n\n# To read into a pandas DataFrame\ndata, metadata = csvy.read_to_dataframe(\"important_data.csv\")\n\n# To read into a polars LazyFrame\ndata, metadata = csvy.read_to_polars(\"important_data.csv\")\n\n# To read into a polars DataFrame\ndata, metadata = csvy.read_to_polars(\"important_data.csv\", eager=True)\n</code></pre> <p>The appropriate writer/reader will be selected based on the type of <code>data</code>:</p> <ul> <li>numpy array: <code>np.savetxt</code> and <code>np.loadtxt</code></li> <li>pandas DataFrame: <code>pd.DataFrame.to_csv</code> and <code>pd.read_csv</code></li> <li>polars DataFrame/LazyFrame: <code>pl.DataFrame.write_csv</code> and <code>pl.scan_csv</code></li> <li>nested lists:' <code>csv.writer</code> and <code>csv.reader</code></li> </ul> <p>Options can be passed to the tabular data writer/reader by setting the <code>csv_options</code> dictionary. Likewise you can set the <code>yaml_options</code> dictionary with whatever options you want to pass to <code>yaml.safe_load</code> and <code>yaml.safe_dump</code> functions, reading/writing the YAML-formatted header, respectively.</p> <p>You can also instruct a writer to use line buffering, instead of the usual chunk buffering.</p> <p>Finally, you can control the character(s) used to indicate comments by setting the <code>comment</code> keyword when writing a file. By default, there is no character (\"\"). During reading, the comment character is found automatically.</p> <p>Note that, by default, these reader functions will assume UTF-8 encoding. You can choose a different character encoding by setting the <code>encoding</code> keyword argument to any of these reader or writer functions. For example, on Windows, Windows-1252 encoding is often used, which can be specified via <code>encoding='cp1252'</code>.</p>"},{"location":"#contributors","title":"Contributors \u2728","text":"<p>Thanks goes to these wonderful people (emoji key):</p> <sub>Diego Alonso \u00c1lvarez</sub>\ud83d\ude87 \ud83e\udd14 \ud83d\udea7 \u26a0\ufe0f \ud83d\udc1b \ud83d\udcbb <sub>Alex Dewar</sub>\ud83e\udd14 \u26a0\ufe0f \ud83d\udcbb <sub>Adrian D'Alessandro</sub>\ud83d\udc1b \ud83d\udcbb \ud83d\udcd6 <sub>James Paul Turner</sub>\ud83d\ude87 \ud83d\udcbb <sub>Dan Cummins</sub>\ud83d\ude87 \ud83d\udcbb <sub>mikeheyns</sub>\ud83d\ude87 <p>This project follows the all-contributors specification. Contributions of any kind welcome!</p>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>csvy<ul> <li>readers</li> <li>validators</li> <li>writers</li> </ul> </li> </ul>"},{"location":"reference/csvy/","title":"csvy","text":""},{"location":"reference/csvy/#csvy","title":"<code>csvy</code>","text":"<p>Python reader/writer for CSV files with YAML header information.</p>"},{"location":"reference/csvy/#csvy-classes","title":"Classes","text":""},{"location":"reference/csvy/#csvy-functions","title":"Functions","text":""},{"location":"reference/csvy/readers/","title":"readers","text":""},{"location":"reference/csvy/readers/#csvy.readers","title":"<code>csvy.readers</code>","text":"<p>A collection of functions for parsing CSVY files.</p>"},{"location":"reference/csvy/readers/#csvy.readers-functions","title":"Functions","text":""},{"location":"reference/csvy/readers/#csvy.readers.get_comment","title":"<code>get_comment(line, marker='---')</code>","text":"<p>Retrieve the comment character used in the header.</p> <p>Given that we know the header limiting markers are '---' it is possible to automatically find out the comment character by simply retrieving what is before the first occurrence of the marker. So, if we find '# ---', then we know that the comment characters are '# '.</p> <p>This will save the user to having to check the file before reading it.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>str</code> <p>Line of text, typically the first one of the file.</p> required <code>marker</code> <code>str</code> <p>The marker characters that indicate the yaml header.</p> <code>'---'</code> <p>Returns:</p> Type Description <code>str</code> <p>The comment character found.</p> Source code in <code>csvy/readers.py</code> <pre><code>def get_comment(line: str, marker: str = \"---\") -&gt; str:\n    \"\"\"Retrieve the comment character used in the header.\n\n    Given that we know the header limiting markers are '---' it is possible to\n    automatically find out the comment character by simply retrieving what is\n    before the first occurrence of the marker. So, if we find '# ---', then we\n    know that the comment characters are '# '.\n\n    This will save the user to having to check the file before reading it.\n\n    Args:\n        line: Line of text, typically the first one of the file.\n        marker: The marker characters that indicate the yaml header.\n\n    Returns:\n        The comment character found.\n\n    \"\"\"\n    if marker not in line:\n        raise ValueError(f\"Yaml header marker '{marker}' not found in line '{line}'.\")\n    else:\n        return \"\" if line.startswith(marker) else line.split(marker)[0]\n</code></pre>"},{"location":"reference/csvy/readers/#csvy.readers.read_header","title":"<code>read_header(filename, marker='---', encoding='utf-8', **kwargs)</code>","text":"<p>Read the yaml-formatted header from a file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Name of the file to read the header from.</p> required <code>marker</code> <code>str</code> <p>The marker characters that indicate the yaml header.</p> <code>'---'</code> <code>encoding</code> <code>str</code> <p>The character encoding in the file to read.</p> <code>'utf-8'</code> <code>**kwargs</code> <code>Any</code> <p>Arguments to pass to 'yaml.safe_load'.</p> <code>{}</code> <p>Returns:</p> Type Description <code>tuple[dict[str, Any], int, str]</code> <p>Tuple containing: a dictionary with the header information, the number of header lines, and the comment character.</p> Source code in <code>csvy/readers.py</code> <pre><code>def read_header(\n    filename: Path | str, marker: str = \"---\", encoding: str = \"utf-8\", **kwargs: Any\n) -&gt; tuple[dict[str, Any], int, str]:\n    \"\"\"Read the yaml-formatted header from a file.\n\n    Args:\n        filename: Name of the file to read the header from.\n        marker: The marker characters that indicate the yaml header.\n        encoding: The character encoding in the file to read.\n        **kwargs: Arguments to pass to 'yaml.safe_load'.\n\n    Returns:\n        Tuple containing: a dictionary with the header information, the number of header\n            lines, and the comment character.\n\n    \"\"\"\n    header = []\n    markers = 0\n    nlines = 0\n    comment = \"\"\n    with Path(filename).open(\"r\", encoding=encoding) as f:\n        for line in f:\n            if nlines == 0:\n                comment = get_comment(line, marker=marker)\n\n            nlines += 1\n            if line.startswith(f\"{comment}{marker}\\n\"):\n                markers += 1\n                if markers == 2:\n                    break\n\n            line = line.lstrip(comment)\n            header.append(line)\n\n    return validate_read(yaml.safe_load(\"\".join(header), **kwargs)), nlines, comment\n</code></pre>"},{"location":"reference/csvy/readers/#csvy.readers.read_metadata","title":"<code>read_metadata(filename, marker='---', encoding='utf-8', **kwargs)</code>","text":"<p>Read the yaml-formatted metadata from a file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Name of the file to read the header from.</p> required <code>marker</code> <code>str</code> <p>The marker characters that indicate the yaml header.</p> <code>'---'</code> <code>encoding</code> <code>str</code> <p>The character encoding in the file to read.</p> <code>'utf-8'</code> <code>**kwargs</code> <code>Any</code> <p>Arguments to pass to 'yaml.safe_load'.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The metadata stored in the header.</p> Source code in <code>csvy/readers.py</code> <pre><code>def read_metadata(\n    filename: Path | str, marker: str = \"---\", encoding: str = \"utf-8\", **kwargs: Any\n) -&gt; dict[str, Any]:\n    \"\"\"Read the yaml-formatted metadata from a file.\n\n    Args:\n        filename: Name of the file to read the header from.\n        marker: The marker characters that indicate the yaml header.\n        encoding: The character encoding in the file to read.\n        **kwargs: Arguments to pass to 'yaml.safe_load'.\n\n    Returns:\n        The metadata stored in the header.\n\n    \"\"\"\n    return read_header(filename, marker, encoding, **kwargs)[0]\n</code></pre>"},{"location":"reference/csvy/readers/#csvy.readers.read_to_array","title":"<code>read_to_array(filename, marker='---', encoding='utf-8', csv_options=None, yaml_options=None)</code>","text":"<p>Read a CSVY file into dict with the header and array with the data.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Name of the file to read.</p> required <code>marker</code> <code>str</code> <p>The marker characters that indicate the yaml header.</p> <code>'---'</code> <code>encoding</code> <code>str</code> <p>The character encoding in the file to read.</p> <code>'utf-8'</code> <code>csv_options</code> <code>dict[str, Any] | None</code> <p>Options to pass to np.loadtxt.</p> <code>None</code> <code>yaml_options</code> <code>dict[str, Any] | None</code> <p>Options to pass to yaml.safe_load.</p> <code>None</code> <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>If numpy is not found.</p> <p>Returns:</p> Type Description <code>tuple[NDArray, dict[str, Any]]</code> <p>Tuple containing: The numpy array and the header as a dictionary.</p> Source code in <code>csvy/readers.py</code> <pre><code>def read_to_array(\n    filename: Path | str,\n    marker: str = \"---\",\n    encoding: str = \"utf-8\",\n    csv_options: dict[str, Any] | None = None,\n    yaml_options: dict[str, Any] | None = None,\n) -&gt; tuple[NDArray, dict[str, Any]]:\n    \"\"\"Read a CSVY file into dict with the header and array with the data.\n\n    Args:\n        filename:  Name of the file to read.\n        marker: The marker characters that indicate the yaml header.\n        encoding: The character encoding in the file to read.\n        csv_options: Options to pass to np.loadtxt.\n        yaml_options: Options to pass to yaml.safe_load.\n\n    Raises:\n        ModuleNotFoundError: If numpy is not found.\n\n    Returns:\n        Tuple containing: The numpy array and the header as a dictionary.\n\n    \"\"\"\n    if NDArray is None:\n        raise ModuleNotFoundError(\n            \"Module numpy is not present. Install it to read data into an array.\"\n        )\n    import numpy as np\n\n    yaml_options = yaml_options if yaml_options is not None else {}\n    header, nlines, comment = read_header(\n        filename, marker=marker, encoding=encoding, **yaml_options\n    )\n\n    options = csv_options.copy() if csv_options is not None else {}\n    options[\"skiprows\"] = nlines + options.get(\"skiprows\", 0)\n    options[\"comments\"] = comment[0] if len(comment) &gt;= 1 else \"#\"\n    return np.loadtxt(filename, encoding=encoding, **options), header\n</code></pre>"},{"location":"reference/csvy/readers/#csvy.readers.read_to_dataframe","title":"<code>read_to_dataframe(filename, marker='---', encoding='utf-8', csv_options=None, yaml_options=None)</code>","text":"<p>Read a CSVY file into dict with the header and a DataFrame with the data.</p> <p>Possible 'skiprows' and 'comment' argument provided in the 'csv_options' dictionary will be ignored.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Name of the file to read.</p> required <code>marker</code> <code>str</code> <p>The marker characters that indicate the yaml header.</p> <code>'---'</code> <code>encoding</code> <code>str</code> <p>The character encoding in the file to read.</p> <code>'utf-8'</code> <code>csv_options</code> <code>dict[str, Any] | None</code> <p>Options to pass to pd.read_csv.</p> <code>None</code> <code>yaml_options</code> <code>dict[str, Any] | None</code> <p>Options to pass to yaml.safe_load.</p> <code>None</code> <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>If pandas is not found.</p> <p>Returns:</p> Type Description <code>tuple[DataFrame, dict[str, Any]]</code> <p>Tuple containing: The pandas DataFrame and the header as a dictionary.</p> Source code in <code>csvy/readers.py</code> <pre><code>def read_to_dataframe(\n    filename: Path | str,\n    marker: str = \"---\",\n    encoding: str = \"utf-8\",\n    csv_options: dict[str, Any] | None = None,\n    yaml_options: dict[str, Any] | None = None,\n) -&gt; tuple[DataFrame, dict[str, Any]]:\n    \"\"\"Read a CSVY file into dict with the header and a DataFrame with the data.\n\n    Possible 'skiprows' and 'comment' argument provided in the 'csv_options' dictionary\n    will be ignored.\n\n    Args:\n        filename:  Name of the file to read.\n        marker: The marker characters that indicate the yaml header.\n        encoding: The character encoding in the file to read.\n        csv_options: Options to pass to pd.read_csv.\n        yaml_options: Options to pass to yaml.safe_load.\n\n    Raises:\n        ModuleNotFoundError: If pandas is not found.\n\n    Returns:\n        Tuple containing: The pandas DataFrame and the header as a dictionary.\n\n    \"\"\"\n    if DataFrame is None:\n        raise ModuleNotFoundError(\n            \"Module pandas is not present. Install it to read data into DataFrame.\"\n        )\n    import pandas as pd\n\n    yaml_options = yaml_options if yaml_options is not None else {}\n    header, nlines, comment = read_header(\n        filename, marker=marker, encoding=encoding, **yaml_options\n    )\n\n    options = csv_options.copy() if csv_options is not None else {}\n    options[\"skiprows\"] = nlines\n    options[\"comment\"] = comment[0] if len(comment) &gt;= 1 else None\n    return pd.read_csv(filename, encoding=encoding, **options), header\n</code></pre>"},{"location":"reference/csvy/readers/#csvy.readers.read_to_list","title":"<code>read_to_list(filename, marker='---', encoding='utf-8', csv_options=None, yaml_options=None)</code>","text":"<p>Read a CSVY file into a list with the header and a nested list with the data.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Name of the file to read.</p> required <code>marker</code> <code>str</code> <p>The marker characters that indicate the yaml header.</p> <code>'---'</code> <code>encoding</code> <code>str</code> <p>The character encoding in the file to read.</p> <code>'utf-8'</code> <code>csv_options</code> <code>dict[str, Any] | None</code> <p>Options to pass to csv.reader.</p> <code>None</code> <code>yaml_options</code> <code>dict[str, Any] | None</code> <p>Options to pass to yaml.safe_load.</p> <code>None</code> <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>If numpy is not found.</p> <p>Returns:</p> Type Description <code>tuple[list[list], dict[str, Any]]</code> <p>Tuple containing: The nested list and the header as a dictionary.</p> Source code in <code>csvy/readers.py</code> <pre><code>def read_to_list(\n    filename: Path | str,\n    marker: str = \"---\",\n    encoding: str = \"utf-8\",\n    csv_options: dict[str, Any] | None = None,\n    yaml_options: dict[str, Any] | None = None,\n) -&gt; tuple[list[list], dict[str, Any]]:\n    \"\"\"Read a CSVY file into a list with the header and a nested list with the data.\n\n    Args:\n        filename: Name of the file to read.\n        marker: The marker characters that indicate the yaml header.\n        encoding: The character encoding in the file to read.\n        csv_options: Options to pass to csv.reader.\n        yaml_options: Options to pass to yaml.safe_load.\n\n    Raises:\n        ModuleNotFoundError: If numpy is not found.\n\n    Returns:\n        Tuple containing: The nested list and the header as a dictionary.\n\n    \"\"\"\n    import csv\n\n    yaml_options = yaml_options if yaml_options is not None else {}\n    header, nlines, _ = read_header(\n        filename, marker=marker, encoding=encoding, **yaml_options\n    )\n\n    options = csv_options.copy() if csv_options is not None else {}\n\n    data = []\n    with open(filename, encoding=encoding, newline=\"\") as csvfile:\n        csvreader = csv.reader(csvfile, **options)\n\n        for _ in range(nlines):\n            next(csvreader)\n\n        for row in csvreader:\n            data.append(row)\n\n    return data, header\n</code></pre>"},{"location":"reference/csvy/readers/#csvy.readers.read_to_polars","title":"<code>read_to_polars(filename, marker='---', encoding='utf8', csv_options=None, yaml_options=None, eager=False)</code>","text":"<p>Read a CSVY file into dict with the header and a Polars LazyFrame with the data.</p> <p>This uses the <code>scan_csv</code> method from Polars to read the data. This returns a polars LazyFrame, which means the data is not loaded into memory until it is needed. To load the data into memory, set the <code>eager</code> parameter to <code>True</code>.</p> <p>Possible 'skip_rows' and 'comment_prefix' argument provided in the 'csv_options' dictionary will be ignored.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Name of the file to read.</p> required <code>marker</code> <code>str</code> <p>The marker characters that indicate the yaml header.</p> <code>'---'</code> <code>encoding</code> <code>Literal['utf8', 'utf8-lossy']</code> <p>The character encoding in the file to read.</p> <code>'utf8'</code> <code>csv_options</code> <code>dict[str, Any] | None</code> <p>Options to pass to pl.scan_csv.</p> <code>None</code> <code>yaml_options</code> <code>dict[str, Any] | None</code> <p>Options to pass to yaml.safe_load.</p> <code>None</code> <code>eager</code> <code>bool</code> <p>Whether to load the data into memory.</p> <code>False</code> <p>Raises:</p> Type Description <code>ModuleNotFoundError</code> <p>If polars is not found.</p> <code>ValueError</code> <p>If an invalid character encoding is specified.</p> <p>Returns:</p> Type Description <code>tuple[LazyFrame | DataFrame, dict[str, Any]]</code> <p>Tuple containing: The polars LazyFrame and the header as a dictionary.</p> Source code in <code>csvy/readers.py</code> <pre><code>def read_to_polars(\n    filename: Path | str,\n    marker: str = \"---\",\n    encoding: Literal[\"utf8\", \"utf8-lossy\"] = \"utf8\",\n    csv_options: dict[str, Any] | None = None,\n    yaml_options: dict[str, Any] | None = None,\n    eager: bool = False,\n) -&gt; tuple[LazyFrame | PolarsDataFrame, dict[str, Any]]:\n    \"\"\"Read a CSVY file into dict with the header and a Polars LazyFrame with the data.\n\n    This uses the `scan_csv` method from Polars to read the data. This returns a polars\n    LazyFrame, which means the data is not loaded into memory until it is needed. To\n    load the data into memory, set the `eager` parameter to `True`.\n\n    Possible 'skip_rows' and 'comment_prefix' argument provided in the 'csv_options'\n    dictionary will be ignored.\n\n    Args:\n        filename:  Name of the file to read.\n        marker: The marker characters that indicate the yaml header.\n        encoding: The character encoding in the file to read.\n        csv_options: Options to pass to pl.scan_csv.\n        yaml_options: Options to pass to yaml.safe_load.\n        eager: Whether to load the data into memory.\n\n    Raises:\n        ModuleNotFoundError: If polars is not found.\n        ValueError: If an invalid character encoding is specified.\n\n    Returns:\n        Tuple containing: The polars LazyFrame and the header as a dictionary.\n\n    \"\"\"\n    if encoding not in (\"utf8\", \"utf8-lossy\"):\n        raise ValueError(\"Encoding must be either 'utf8' or 'utf8-lossy'\")\n\n    if LazyFrame is None:\n        raise ModuleNotFoundError(\n            \"Module polars is not present. Install it to read data into DataFrame.\"\n        )\n    import polars as pl\n\n    yaml_options = yaml_options if yaml_options is not None else {}\n    header, nlines, comment = read_header(\n        filename, marker=marker, encoding=\"utf-8\", **yaml_options\n    )\n\n    options = csv_options.copy() if csv_options is not None else {}\n    options[\"skip_rows\"] = nlines\n    options[\"comment_prefix\"] = comment[0] if len(comment) &gt;= 1 else None\n\n    lf = pl.scan_csv(filename, encoding=encoding, **options)\n    if eager:\n        return lf.collect(), header\n    return lf, header\n</code></pre>"},{"location":"reference/csvy/validators/","title":"validators","text":""},{"location":"reference/csvy/validators/#csvy.validators","title":"<code>csvy.validators</code>","text":"<p>Module that contains validators for the CSVY file format.</p>"},{"location":"reference/csvy/validators/#csvy.validators-attributes","title":"Attributes","text":""},{"location":"reference/csvy/validators/#csvy.validators.VALIDATORS_REGISTRY","title":"<code>VALIDATORS_REGISTRY: dict[str, type[BaseModel]] = {}</code>  <code>module-attribute</code>","text":"<p>Registry of validators to run on the header.</p>"},{"location":"reference/csvy/validators/#csvy.validators-classes","title":"Classes","text":""},{"location":"reference/csvy/validators/#csvy.validators.CSVDialectValidator","title":"<code>CSVDialectValidator</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Implements a validator for CSV Dialects.</p> <p>This class is used to validate the CSV Dialects in the CSVY file. It is based on the <code>csv.Dialect</code> class from the Python Standard Library. It does not include the 'quoting' attribute, as it is not serializable as JSON or easy to understand by other tools, but rather a python specific thing.</p> <p>Attributes:</p> Name Type Description <code>delimiter</code> <code>str</code> <p>A one-character string used to separate fields.</p> <code>doublequote</code> <code>bool</code> <p>Controls how instances of quotechar appearing inside a field should themselves be quoted. When True, the character is doubled. When False, the escapechar is used as a prefix to the quotechar. It defaults to True.</p> <code>escapechar</code> <code>Optional[str]</code> <p>A one-character string used by the writer to escape the delimiter. It defaults to None.</p> <code>lineterminator</code> <code>str</code> <p>The string used to terminate lines produced by the writer. It defaults to '\\r\\n'.</p> <code>quotechar</code> <code>str</code> <p>A one-character string used to quote fields containing special characters, such as the delimiter or quotechar, or which contain new-line characters. It defaults to '\"'.</p> <code>skipinitialspace</code> <code>bool</code> <p>When True, whitespace immediately following the delimiter is ignored. It defaults to False.</p>"},{"location":"reference/csvy/validators/#csvy.validators.CSVDialectValidator-functions","title":"Functions","text":""},{"location":"reference/csvy/validators/#csvy.validators.CSVDialectValidator.excel","title":"<code>excel()</code>  <code>classmethod</code>","text":"<p>Return a validator for the Excel CSV Dialect.</p> <p>This method returns a validator for the Excel CSV Dialect, which is a common dialect used in Excel files.</p> <p>Returns:</p> Type Description <code>T</code> <p>A validator for the Excel CSV Dialect.</p> Source code in <code>csvy/validators.py</code> <pre><code>@classmethod\ndef excel(cls: type[T]) -&gt; T:\n    \"\"\"Return a validator for the Excel CSV Dialect.\n\n    This method returns a validator for the Excel CSV Dialect, which is a common\n    dialect used in Excel files.\n\n    Returns:\n        A validator for the Excel CSV Dialect.\n\n    \"\"\"\n    excel = csv.excel()\n    return cls(\n        delimiter=excel.delimiter,\n        doublequote=excel.doublequote,\n        escapechar=excel.escapechar,\n        lineterminator=excel.lineterminator,\n        quotechar=excel.quotechar or '\"',\n        skipinitialspace=excel.skipinitialspace,\n    )\n</code></pre>"},{"location":"reference/csvy/validators/#csvy.validators.CSVDialectValidator.excel_tab","title":"<code>excel_tab()</code>  <code>classmethod</code>","text":"<p>Return a validator for the Excel Tab CSV Dialect.</p> <p>This method returns a validator for the Excel Tab CSV Dialect, which is a common dialect used in Excel files with tab delimiters.</p> <p><code>excel</code> has not parameter <code>strict</code> so that one is ignored.</p> <p>Returns:</p> Type Description <code>T</code> <p>A validator for the Excel Tab CSV Dialect.</p> Source code in <code>csvy/validators.py</code> <pre><code>@classmethod\ndef excel_tab(cls: type[T]) -&gt; T:\n    \"\"\"Return a validator for the Excel Tab CSV Dialect.\n\n    This method returns a validator for the Excel Tab CSV Dialect, which is a common\n    dialect used in Excel files with tab delimiters.\n\n    `excel` has not parameter `strict` so that one is ignored.\n\n    Returns:\n        A validator for the Excel Tab CSV Dialect.\n\n    \"\"\"\n    excel_tab = csv.excel_tab()\n    return cls(\n        delimiter=excel_tab.delimiter,\n        doublequote=excel_tab.doublequote,\n        escapechar=excel_tab.escapechar,\n        lineterminator=excel_tab.lineterminator,\n        quotechar=excel_tab.quotechar or '\"',\n        skipinitialspace=excel_tab.skipinitialspace,\n    )\n</code></pre>"},{"location":"reference/csvy/validators/#csvy.validators.CSVDialectValidator.to_dialect","title":"<code>to_dialect()</code>","text":"<p>Convert the validator to a custom csv.Dialect object.</p> <p>This method converts the validator to a custom csv.Dialect object that can be used to read or write CSV files with the specified dialect.</p> <p>For 'quoting', the default value is used, as it is not serializable.</p> <p>Returns:</p> Type Description <code>Dialect</code> <p>A custom csv.Dialect object with the specified attributes.</p> Source code in <code>csvy/validators.py</code> <pre><code>def to_dialect(self) -&gt; csv.Dialect:\n    \"\"\"Convert the validator to a custom csv.Dialect object.\n\n    This method converts the validator to a custom csv.Dialect object that can be\n    used to read or write CSV files with the specified dialect.\n\n    For 'quoting', the default value is used, as it is not serializable.\n\n    Returns:\n        A custom csv.Dialect object with the specified attributes.\n\n    \"\"\"\n    dialect = type(\n        \"CustomDialect\",\n        (csv.Dialect,),\n        {\n            \"delimiter\": self.delimiter,\n            \"doublequote\": self.doublequote,\n            \"escapechar\": self.escapechar,\n            \"lineterminator\": self.lineterminator,\n            \"quotechar\": self.quotechar,\n            \"skipinitialspace\": self.skipinitialspace,\n            \"quoting\": csv.QUOTE_MINIMAL,  # This is not serializable.\n        },\n    )\n    return dialect()\n</code></pre>"},{"location":"reference/csvy/validators/#csvy.validators.CSVDialectValidator.unix_dialect","title":"<code>unix_dialect()</code>  <code>classmethod</code>","text":"<p>Return a validator for the Unix CSV Dialect.</p> <p>This method returns a validator for the Unix CSV Dialect, which is a common dialect used in Unix files.</p> <p>Returns:</p> Type Description <code>T</code> <p>A validator for the Unix CSV Dialect.</p> Source code in <code>csvy/validators.py</code> <pre><code>@classmethod\ndef unix_dialect(cls: type[T]) -&gt; T:\n    \"\"\"Return a validator for the Unix CSV Dialect.\n\n    This method returns a validator for the Unix CSV Dialect, which is a common\n    dialect used in Unix files.\n\n    Returns:\n        A validator for the Unix CSV Dialect.\n\n    \"\"\"\n    unix = csv.unix_dialect()\n    return cls(\n        delimiter=unix.delimiter,\n        doublequote=unix.doublequote,\n        escapechar=unix.escapechar,\n        lineterminator=unix.lineterminator,\n        quotechar=unix.quotechar or '\"',\n        skipinitialspace=unix.skipinitialspace,\n    )\n</code></pre>"},{"location":"reference/csvy/validators/#csvy.validators-functions","title":"Functions","text":""},{"location":"reference/csvy/validators/#csvy.validators.register_validator","title":"<code>register_validator(name, overwrite=False)</code>","text":"<p>Register a validator in the registry.</p> <p>This function is a decorator that registers a validator in the registry. The name of the validator is used as the key in the registry.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the validator.</p> required <code>overwrite</code> <code>bool</code> <p>Whether to overwrite the validator if it already exists.</p> <code>False</code> <p>Returns:</p> Type Description <code>Callable[[type[BaseModel]], type[BaseModel]]</code> <p>The decorator function that registers the validator.</p> Source code in <code>csvy/validators.py</code> <pre><code>def register_validator(\n    name: str, overwrite: bool = False\n) -&gt; Callable[[type[BaseModel]], type[BaseModel]]:\n    \"\"\"Register a validator in the registry.\n\n    This function is a decorator that registers a validator in the registry. The name\n    of the validator is used as the key in the registry.\n\n    Args:\n        name: The name of the validator.\n        overwrite: Whether to overwrite the validator if it already exists.\n\n    Returns:\n        The decorator function that registers the validator.\n\n    \"\"\"\n\n    def decorator(cls: type[BaseModel]) -&gt; type[BaseModel]:\n        if not issubclass(cls, BaseModel):\n            raise TypeError(\"Validators must be subclasses of pydantic.BaseModel.\")\n\n        if name in VALIDATORS_REGISTRY and not overwrite:\n            raise ValueError(f\"Validator with name '{name}' already exists.\")\n\n        VALIDATORS_REGISTRY[name] = cls\n        return cls\n\n    return decorator\n</code></pre>"},{"location":"reference/csvy/validators/#csvy.validators.validate_read","title":"<code>validate_read(header)</code>","text":"<p>Run the validators on the header in a read operation.</p> <p>This function runs the validators on the header. It uses the keys of the header to find the validators in the registry and runs them on the corresponding values.</p> <p>Parameters:</p> Name Type Description Default <code>header</code> <code>dict[str, Any]</code> <p>The header of the CSVY file.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The validated header.</p> Source code in <code>csvy/validators.py</code> <pre><code>def validate_read(header: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"Run the validators on the header in a read operation.\n\n    This function runs the validators on the header. It uses the keys of the header to\n    find the validators in the registry and runs them on the corresponding values.\n\n    Args:\n        header: The header of the CSVY file.\n\n    Returns:\n        The validated header.\n\n    \"\"\"\n    validated_header = {}\n    for key, value in header.items():\n        if key in VALIDATORS_REGISTRY:\n            validator = VALIDATORS_REGISTRY[key]\n            validated_header[key] = validator(**value)\n        else:\n            validated_header[key] = value\n    return validated_header\n</code></pre>"},{"location":"reference/csvy/validators/#csvy.validators.validate_write","title":"<code>validate_write(header)</code>","text":"<p>Use the validators to create the header in a write operation.</p> <p>Transforms the header with validators to a header with dictionaries that can be saved as yaml. It is the reversed operation of validate_read, so calling validate_write(validate_read(header)) should return the original header.</p> <p>Parameters:</p> Name Type Description Default <code>header</code> <code>dict[str, Any]</code> <p>Dictionary to be saved as the header of the CSVY file.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The validated header.</p> Source code in <code>csvy/validators.py</code> <pre><code>def validate_write(header: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"Use the validators to create the header in a write operation.\n\n    Transforms the header with validators to a header with dictionaries that can be\n    saved as yaml. It is the reversed operation of validate_read, so calling\n    validate_write(validate_read(header)) should return the original header.\n\n    Args:\n        header: Dictionary to be saved as the header of the CSVY file.\n\n    Returns:\n        The validated header.\n\n    \"\"\"\n    validated_header = {}\n    for key, value in header.items():\n        validated_header[key] = (\n            value.model_dump() if isinstance(value, BaseModel) else value\n        )\n    return validated_header\n</code></pre>"},{"location":"reference/csvy/writers/","title":"writers","text":""},{"location":"reference/csvy/writers/#csvy.writers","title":"<code>csvy.writers</code>","text":"<p>A collection of functions for writing CSVY files.</p>"},{"location":"reference/csvy/writers/#csvy.writers-classes","title":"Classes","text":""},{"location":"reference/csvy/writers/#csvy.writers.Writer","title":"<code>Writer(filename, header, comment='', encoding='utf-8', csv_options=None, yaml_options=None, line_buffering=False)</code>","text":"<p>A class for writing the CSV data to a file incrementally.</p> <p>Under the hood, this class uses csv.writer to write lines of data to CSV files.</p> <p>Create a new Writer.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Path to file. If it exists it will be overwritten.</p> required <code>header</code> <code>dict[str, Any]</code> <p>Dictionary with the header information to save.</p> required <code>comment</code> <code>str</code> <p>String to use to mark the header lines as comments.</p> <code>''</code> <code>encoding</code> <code>str</code> <p>The character encoding to use when writing to file.</p> <code>'utf-8'</code> <code>csv_options</code> <code>dict[str, Any] | None</code> <p>Arguments to pass to csv.writer()</p> <code>None</code> <code>yaml_options</code> <code>dict[str, Any] | None</code> <p>Arguments to pass to the 'yaml.safe_dump' function to control writing the header.</p> <code>None</code> <code>line_buffering</code> <code>bool</code> <p>Line buffering instead of chunk buffering (default False).</p> <code>False</code> Source code in <code>csvy/writers.py</code> <pre><code>def __init__(\n    self,\n    filename: Path | str,\n    header: dict[str, Any],\n    comment: str = \"\",\n    encoding: str = \"utf-8\",\n    csv_options: dict[str, Any] | None = None,\n    yaml_options: dict[str, Any] | None = None,\n    line_buffering: bool = False,\n) -&gt; None:\n    \"\"\"Create a new Writer.\n\n    Args:\n        filename: Path to file. If it exists it will be overwritten.\n        header: Dictionary with the header information to save.\n        comment: String to use to mark the header lines as comments.\n        encoding: The character encoding to use when writing to file.\n        csv_options: Arguments to pass to csv.writer()\n        yaml_options: Arguments to pass to the 'yaml.safe_dump' function to control\n            writing the header.\n        line_buffering: Line buffering instead of chunk buffering (default False).\n\n    \"\"\"\n    if not csv_options:\n        csv_options = {}\n    if not yaml_options:\n        yaml_options = {}\n\n    # Line buffering: 1 and default chunk buffering: -1\n    buffering = 1 if line_buffering else -1\n\n    # Newline must be \"\" as per csv.writer's documentation\n    self._file = Path(filename).open(\n        \"w\", encoding=encoding, newline=\"\", buffering=buffering\n    )\n    write_header(self._file, header, comment, encoding, **yaml_options)\n\n    self._writer = csv.writer(self._file, **csv_options)\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers.Writer-functions","title":"Functions","text":""},{"location":"reference/csvy/writers/#csvy.writers.Writer.__enter__","title":"<code>__enter__()</code>","text":"<p>Enter the context manager.</p> Source code in <code>csvy/writers.py</code> <pre><code>def __enter__(self) -&gt; Writer:\n    \"\"\"Enter the context manager.\"\"\"\n    return self\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers.Writer.__exit__","title":"<code>__exit__(*_)</code>","text":"<p>Exit the context manager.</p> Source code in <code>csvy/writers.py</code> <pre><code>def __exit__(self, *_: Any) -&gt; None:\n    \"\"\"Exit the context manager.\"\"\"\n    self._file.close()\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers.Writer.close","title":"<code>close()</code>","text":"<p>Close the underlying file handle.</p> Source code in <code>csvy/writers.py</code> <pre><code>def close(self) -&gt; None:\n    \"\"\"Close the underlying file handle.\"\"\"\n    self._file.close()\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers.Writer.writerow","title":"<code>writerow(row)</code>","text":"<p>Write a single row of data to the CSV file.</p> Source code in <code>csvy/writers.py</code> <pre><code>def writerow(self, row: Iterable[Any]) -&gt; None:\n    \"\"\"Write a single row of data to the CSV file.\"\"\"\n    self._writer.writerow(row)\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers.Writer.writerows","title":"<code>writerows(rows)</code>","text":"<p>Write multiple rows of data to the CSV file.</p> Source code in <code>csvy/writers.py</code> <pre><code>def writerows(self, rows: Iterable[Iterable[Any]]) -&gt; None:\n    \"\"\"Write multiple rows of data to the CSV file.\"\"\"\n    self._writer.writerows(rows)\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers-functions","title":"Functions","text":""},{"location":"reference/csvy/writers/#csvy.writers.register_writer","title":"<code>register_writer(fun)</code>","text":"<p>Register a file writer.</p> <p>Parameters:</p> Name Type Description Default <code>fun</code> <code>Callable</code> <p>The writer function.</p> required <p>Returns:</p> Name Type Description <code>Callable</code> <code>Callable</code> <p>the writer function.</p> Source code in <code>csvy/writers.py</code> <pre><code>def register_writer(fun: Callable[[Path | str, Any, str], bool]) -&gt; Callable:\n    \"\"\"Register a file writer.\n\n    Args:\n        fun (Callable): The writer function.\n\n    Returns:\n        Callable: the writer function.\n\n    \"\"\"\n    if fun not in KNOWN_WRITERS:\n        KNOWN_WRITERS.append(fun)\n    return fun\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers.write","title":"<code>write(filename, data, header, comment='', encoding='utf-8', csv_options=None, yaml_options=None)</code>","text":"<p>Write the data and header in a CSV file, formating the header as yaml.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Name of the file to save the information into. If it exists, it will be overwritten.</p> required <code>data</code> <code>Any</code> <p>The data to add to the file.</p> required <code>header</code> <code>dict[str, Any]</code> <p>Dictionary with the header information to save.</p> required <code>comment</code> <code>str</code> <p>String to use to mark the header lines as comments.</p> <code>''</code> <code>encoding</code> <code>str</code> <p>The character encoding to use in the file to write.</p> <code>'utf-8'</code> <code>csv_options</code> <code>dict[str, Any] | None</code> <p>Arguments to pass to the CSV writer, being this <code>savetxt</code>, panda's <code>to_csv</code> or something else. Mind that any argument related to the character to indicate a comment or header line will be ignored.</p> <code>None</code> <code>yaml_options</code> <code>dict[str, Any] | None</code> <p>Arguments to pass to the 'yaml.safe_dump' function to control writing the header.</p> <code>None</code> Source code in <code>csvy/writers.py</code> <pre><code>def write(\n    filename: Path | str,\n    data: Any,\n    header: dict[str, Any],\n    comment: str = \"\",\n    encoding: str = \"utf-8\",\n    csv_options: dict[str, Any] | None = None,\n    yaml_options: dict[str, Any] | None = None,\n) -&gt; None:\n    \"\"\"Write the data and header in a CSV file, formating the header as yaml.\n\n    Args:\n        filename: Name of the file to save the information into. If it exists, it will\n            be overwritten.\n        data: The data to add to the file.\n        header: Dictionary with the header information to save.\n        comment: String to use to mark the header lines as comments.\n        encoding: The character encoding to use in the file to write.\n        csv_options: Arguments to pass to the CSV writer, being this `savetxt`, panda's\n            `to_csv` or something else. Mind that any argument related to the character\n            to indicate a comment or header line will be ignored.\n        yaml_options: Arguments to pass to the 'yaml.safe_dump' function to control\n            writing the header.\n\n    \"\"\"\n    csv_options = csv_options if csv_options is not None else {}\n    yaml_options = yaml_options if yaml_options is not None else {}\n\n    write_header(filename, header, comment, encoding, **yaml_options)\n    write_data(filename, data, comment, encoding, **csv_options)\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers.write_csv","title":"<code>write_csv(filename, data, comment='', encoding='utf-8', **kwargs)</code>","text":"<p>Write the tabular to the chosen file, adding it after the header.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Name of the file to save the data into. The data will be added to the end of the file.</p> required <code>data</code> <code>Any</code> <p>The data. Can have anything that counts as a sequence. Each component of the sequence will be saved in a different row.</p> required <code>comment</code> <code>str</code> <p>String to use to mark the header lines as comments.</p> <code>''</code> <code>encoding</code> <code>str</code> <p>The character encoding to use in the file to write.</p> <code>'utf-8'</code> <code>**kwargs</code> <code>Any</code> <p>Arguments to be passed to the underlaying saving method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the writer worked, False otherwise.</p> Source code in <code>csvy/writers.py</code> <pre><code>def write_csv(\n    filename: Path | str,\n    data: Any,\n    comment: str = \"\",\n    encoding: str = \"utf-8\",\n    **kwargs: Any,\n) -&gt; bool:\n    \"\"\"Write the tabular to the chosen file, adding it after the header.\n\n    Args:\n        filename: Name of the file to save the data into. The data will be added to the\n            end of the file.\n        data: The data. Can have anything that counts as a sequence. Each component of\n            the sequence will be saved in a different row.\n        comment: String to use to mark the header lines as comments.\n        encoding: The character encoding to use in the file to write.\n        **kwargs: Arguments to be passed to the underlaying saving method.\n\n    Returns:\n        True if the writer worked, False otherwise.\n\n    \"\"\"\n    with open(filename, \"a\", encoding=encoding, newline=\"\") as f:\n        writer = csv.writer(f, **kwargs)\n        for row in data:\n            writer.writerow(row)\n\n    return True\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers.write_data","title":"<code>write_data(filename, data, comment='', encoding='utf-8', **kwargs)</code>","text":"<p>Write the tabular data to the chosen file, adding it after the header.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Name of the file to save the data into. The data will be added to the end of the file.</p> required <code>data</code> <code>Any</code> <p>The data to add to the file. Depending on its type, a different method will be used to save the data to disk. The fallback will be the built in CSV package. If it is a numpy array, the <code>savetxt</code> will be used, while if it is a pandas Dataframe, the <code>to_csv</code> method will be used.</p> required <code>comment</code> <code>str</code> <p>String to use to mark the header lines as comments.</p> <code>''</code> <code>encoding</code> <code>str</code> <p>The character encoding to use in the file to write.</p> <code>'utf-8'</code> <code>**kwargs</code> <code>Any</code> <p>Arguments to be passed to the underlaying saving method.</p> <code>{}</code> Source code in <code>csvy/writers.py</code> <pre><code>def write_data(\n    filename: Path | str,\n    data: Any,\n    comment: str = \"\",\n    encoding: str = \"utf-8\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Write the tabular data to the chosen file, adding it after the header.\n\n    Args:\n        filename: Name of the file to save the data into. The data will be added to the\n            end of the file.\n        data: The data to add to the file. Depending on its type, a different method\n            will be used to save the data to disk. The fallback will be the built in CSV\n            package. If it is a numpy array, the `savetxt` will be used, while if it is\n            a pandas Dataframe, the `to_csv` method will be used.\n        comment: String to use to mark the header lines as comments.\n        encoding: The character encoding to use in the file to write.\n        **kwargs: Arguments to be passed to the underlaying saving method.\n\n    \"\"\"\n    for fun in KNOWN_WRITERS:\n        if fun(filename, data, comment, **kwargs):\n            return\n\n    write_csv(filename, data, comment, encoding, **kwargs)\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers.write_header","title":"<code>write_header(file, header, comment='', encoding='utf-8', **kwargs)</code>","text":"<p>Write the header dictionary into the file with lines starting with comment.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>Path | str | TextIOBase</code> <p>File handle or path to file. Will be overwritten if it exists.</p> required <code>header</code> <code>dict[str, Any]</code> <p>Dictionary with the header information to save.</p> required <code>comment</code> <code>str</code> <p>String to use to mark the header lines as comments.</p> <code>''</code> <code>encoding</code> <code>str</code> <p>The character encoding to use in the file to write.</p> <code>'utf-8'</code> <code>**kwargs</code> <code>Any</code> <p>Arguments to pass to 'yaml.safe_dump'. If \"sort_keys\" is not one of arguments, it will be set to sort_keys=False.</p> <code>{}</code> Source code in <code>csvy/writers.py</code> <pre><code>def write_header(\n    file: Path | str | TextIOBase,\n    header: dict[str, Any],\n    comment: str = \"\",\n    encoding: str = \"utf-8\",\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Write the header dictionary into the file with lines starting with comment.\n\n    Args:\n        file: File handle or path to file. Will be overwritten if it exists.\n        header: Dictionary with the header information to save.\n        comment: String to use to mark the header lines as comments.\n        encoding: The character encoding to use in the file to write.\n        **kwargs: Arguments to pass to 'yaml.safe_dump'. If \"sort_keys\" is not one of\n            arguments, it will be set to sort_keys=False.\n\n    \"\"\"\n    header_ = validate_write(header)\n    if not isinstance(file, TextIOBase):\n        with Path(file).open(\"w\", encoding=encoding) as f:\n            write_header(f, header_, comment, **kwargs)\n            return\n\n    if \"sort_keys\" not in kwargs:\n        kwargs[\"sort_keys\"] = False\n\n    stream = yaml.safe_dump(header_, **kwargs)\n    stream = \"\\n\".join([f\"{comment}\" + line for line in stream.split(\"\\n\")])\n    marker = f\"{comment}---\\n\"\n    stream = marker + stream + \"---\\n\"\n    file.write(stream)  # type: ignore\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers.write_numpy","title":"<code>write_numpy(filename, data, comment='', encoding='utf-8', **kwargs)</code>","text":"<p>Write the numpy array to the chosen file, adding it after the header.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Name of the file to save the data into. The data will be added to the end of the file.</p> required <code>data</code> <code>Any</code> <p>The data. If it is a numpy array, it will be saved, otherwise nothing is done.</p> required <code>comment</code> <code>str</code> <p>String to use to mark the header lines as comments.</p> <code>''</code> <code>encoding</code> <code>str</code> <p>The character encoding to use in the file to write.</p> <code>'utf-8'</code> <code>**kwargs</code> <code>Any</code> <p>Arguments to be passed to the underlaying saving method.</p> <code>{}</code> Return <p>True if the writer worked, False otherwise.</p> Source code in <code>csvy/writers.py</code> <pre><code>@register_writer\ndef write_numpy(\n    filename: Path | str,\n    data: Any,\n    comment: str = \"\",\n    encoding: str = \"utf-8\",\n    **kwargs: Any,\n) -&gt; bool:\n    \"\"\"Write the numpy array to the chosen file, adding it after the header.\n\n    Args:\n        filename: Name of the file to save the data into. The data will be added to the\n            end of the file.\n        data: The data. If it is a numpy array, it will be saved, otherwise nothing is\n            done.\n        comment: String to use to mark the header lines as comments.\n        encoding: The character encoding to use in the file to write.\n        **kwargs: Arguments to be passed to the underlaying saving method.\n\n    Return:\n        True if the writer worked, False otherwise.\n\n    \"\"\"\n    try:\n        import numpy as np\n\n        kwargs[\"comments\"] = comment\n        if isinstance(data, np.ndarray):\n            with open(filename, \"a\", encoding=encoding) as f:\n                np.savetxt(f, data, **kwargs)\n\n            return True\n\n    except ModuleNotFoundError:\n        logging.getLogger().debug(\"Numpy is not installed, so not using 'savetxt'.\")\n\n    return False\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers.write_pandas","title":"<code>write_pandas(filename, data, comment='', encoding='utf-8', **kwargs)</code>","text":"<p>Write the pandas dataframe to the chosen file, adding it after the header.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Name of the file to save the data into. The data will be added to the end of the file.</p> required <code>data</code> <code>Any</code> <p>The data. If it is a pandas dataframe, it will be saved, otherwise nothing is done.</p> required <code>comment</code> <code>str</code> <p>String to use to mark the header lines as comments.</p> <code>''</code> <code>encoding</code> <code>str</code> <p>The character encoding to use in the file to write.</p> <code>'utf-8'</code> <code>**kwargs</code> <code>Any</code> <p>Arguments to be passed to the underlaying saving method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the writer worked, False otherwise.</p> Source code in <code>csvy/writers.py</code> <pre><code>@register_writer\ndef write_pandas(\n    filename: Path | str,\n    data: Any,\n    comment: str = \"\",\n    encoding: str = \"utf-8\",\n    **kwargs: Any,\n) -&gt; bool:\n    \"\"\"Write the pandas dataframe to the chosen file, adding it after the header.\n\n    Args:\n        filename: Name of the file to save the data into. The data will be added to the\n            end of the file.\n        data: The data. If it is a pandas dataframe, it will be saved, otherwise nothing\n            is done.\n        comment: String to use to mark the header lines as comments.\n        encoding: The character encoding to use in the file to write.\n        **kwargs: Arguments to be passed to the underlaying saving method.\n\n    Returns:\n        True if the writer worked, False otherwise.\n\n    \"\"\"\n    try:\n        import pandas as pd\n\n        if isinstance(data, pd.DataFrame):\n            with open(filename, \"a\", encoding=encoding, newline=\"\") as f:\n                data.to_csv(f, **kwargs)\n\n            return True\n\n    except ModuleNotFoundError:\n        logging.getLogger().debug(\"Pandas is not installed, so not using 'to_csv'.\")\n\n    return False\n</code></pre>"},{"location":"reference/csvy/writers/#csvy.writers.write_polars","title":"<code>write_polars(filename, data, comment='', encoding='utf-8', **kwargs)</code>","text":"<p>Write the polars dataframe to the chosen file, adding it after the header.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>Path | str</code> <p>Name of the file to save the data into. The data will be added to the end of the file.</p> required <code>data</code> <code>Any</code> <p>The data. If it is a polars DataFrame or LazyFrame, it will be saved, otherwise nothing is done.</p> required <code>comment</code> <code>str</code> <p>String to use to mark the header lines as comments.</p> <code>''</code> <code>encoding</code> <code>str</code> <p>The character encoding to use in the file to write.</p> <code>'utf-8'</code> <code>**kwargs</code> <code>Any</code> <p>Arguments to be passed to the underlaying saving method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the writer worked, False otherwise.</p> Source code in <code>csvy/writers.py</code> <pre><code>@register_writer\ndef write_polars(\n    filename: Path | str,\n    data: Any,\n    comment: str = \"\",\n    encoding: str = \"utf-8\",\n    **kwargs: Any,\n) -&gt; bool:\n    \"\"\"Write the polars dataframe to the chosen file, adding it after the header.\n\n    Args:\n        filename: Name of the file to save the data into. The data will be added to the\n            end of the file.\n        data: The data. If it is a polars DataFrame or LazyFrame, it will be saved,\n            otherwise nothing is done.\n        comment: String to use to mark the header lines as comments.\n        encoding: The character encoding to use in the file to write.\n        **kwargs: Arguments to be passed to the underlaying saving method.\n\n    Returns:\n        True if the writer worked, False otherwise.\n\n    \"\"\"\n    try:\n        import polars as pl\n\n        if isinstance(data, pl.LazyFrame):\n            # Streaming mode (saving with `LazyFrame.sink_csv`) is unstable, so we\n            # collect the data into a DataFrame first\n            data = data.collect()\n        if isinstance(data, pl.DataFrame):\n            with open(filename, \"a\", encoding=encoding, newline=\"\") as f:\n                data.write_csv(f, **kwargs)\n\n            return True\n\n    except ModuleNotFoundError:\n        logging.getLogger().debug(\"Polars is not installed, so not using 'write_csv'.\")\n\n    return False\n</code></pre>"}]}